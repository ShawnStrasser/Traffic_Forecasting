---
title: "Final Project Part 2: Predicting Automobile Traffic"
author: "Sreeti Ravi, Shawn Strasser"
date: "3/26/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(fpp3)
library(imputeTS)
library(arrow)
```
```{r dataset}

# Set the system timezone to UTC
Sys.setenv(TZ = "UTC")
#Import Data
dataset <- read_parquet("volumes_traveltime.parquet") %>% 
  filter(TSSU == "03008", Phase == 2) %>% #filter to 1 for now to make this faster
  #select(-Travel_Time) %>%
  as_tsibble(index = TimeStamp, key = c("TSSU", "Phase")) %>%
  #filter DST time change periods due to erratic events 
  filter_index(~ "2019-11-03 00:45:00",
               "2019-11-03 01:45:00" ~ "2020-11-01 00:45:00",
               "2020-11-01 01:45:00" ~ "2021-11-07 00:45:00", 
               "2021-11-07 01:45:00" ~.) %>%
  group_by_key() %>% #without grouping the moving avg .complete=TRUE dosen't work all the time
  mutate("1-day Moving Average Volume" = slider::slide_dbl(Volume, mean, .before=48, .after = 47, .complete = TRUE)) %>%
  mutate("7-day Moving Average Volume" = slider::slide_dbl(Volume, mean, .before=336, .after = 335, .complete = TRUE)) %>%
  mutate("1-day Moving Average Travel Time" = slider::slide_dbl(Travel_Time, mean, .before=48, .after = 47, .complete = TRUE)) %>%
  mutate("7-day Moving Average Travel Time" = slider::slide_dbl(Travel_Time, mean, .before=336, .after = 335, .complete = TRUE)) %>%
  ungroup()
#dataset
```

# 1. Time Series Decomposition

```{r, fig.height=8, fig.width=8}
# Aggregate to hourly to force it to stop using "hour" as a season. should only be day/week/annual
hourly_volume <-dataset %>%
  select(Volume) %>%
  fill_gaps() %>%
  na_locf() %>%
  group_by_key() %>%
  index_by(Hourly_TimeStamp = ~ floor_date(., unit="1 hour")) %>%
  summarise(`Hourly_Volume` = sum(Volume))

# Decomposition example for Hourly Vehicle Traffic Volumes
decomp_volume <- hourly_volume %>%
  model(STL(`Hourly_Volume`, robust = TRUE)) %>% #~ season(period = 96) + season(period = 96 * 7)
  components()


decomp_volume %>%
  #filter(TSSU == "03008", Phase == 2) %>% #filter will be needed later
  filter_index("2022-03") %>%
  autoplot() + 
    labs(
        title = "STL decomposition Example of Traffic Volumes for 03008 during Jan 2022",
        y="Vehicles Per Hour")

#decomp_travel_time %>%
  #filter(TSSU == "03008", Phase == 2) %>%
#  filter_index("2022-01") %>%
#  autoplot() + 
#    labs(
#        title = "STL decomposition Example of Travel Times for for 03008 during Jan 2022",
#        y="Travel Time Minutes")

```


\pagebreak
# 2. Time Series Visualization

This plot reveals some gaps in the data.

```{r}
dataset %>%
  filter(TSSU == "03008", Phase == 2) %>%
  select(Volume) %>%
  as.ts() %>%
  ggplot_na_distribution()
```

\pagebreak
With the exception of holidays and unexpected events, the traffic at this locations is pretty consistent throughout the year. This visual also makes the gaps in data become more apparent.

```{r}
decomp_volume %>%
  #filter(TSSU == "03008", Phase == 2) %>%
  filter_index("2021") %>%
  gg_season(period = 24*7)

```

\pagebreak
ACF plots reveal strong and persistent autocorrelation over days and weeks

```{r fig.width=8}

dataset %>%
  fill_gaps() %>%
  ACF(Volume, lag_max = 96) %>%
  autoplot() + labs(title = "ACF of Volumes for 1 day (96 15-minute periods)")

dataset %>%
  fill_gaps() %>%
  PACF(Volume, lag_max = 96) %>%
  autoplot() + labs(title = "PACF of Volumes for 1 day (96 15-minute periods)")
```


\pagebreak
# 3. Description of Time Series

This plot gives an overview of how traffic volumes change seasonally at a particular location in Salem, OR. 

```{r}
dataset %>%
  filter(TSSU == "03008", Phase == 2) %>%
  autoplot(`1-day Moving Average Volume`, color = "light blue") +
    geom_line(aes(y = `7-day Moving Average Volume`), color = "blue") +
    labs(title = "7-day and 1-day Moving Average Volume for 03008",
        y="Vehicles per 15-minute")

```

Traffic went down during COVID lockdowns March 2020, and again dropped during a wildfire in September 2020. There are regular dips during holidays in the winter and summer, with occasional unexpected dips due to snow on the road.  There is not a strong long term trend present for this location, but there will likely be a trend at other locations.

There is strong seasonality at the levels of day, week, and year. There tends to be more traffic on average during the summer than winter. Weekday traffic is higher than weekend traffic, and midday traffic is higher than night time. 

This time series is not stationary and will require some differencing to become stationary.

\pagebreak
# 4. Model -- apply several models (transformations if needed), explain decisions

## Forecast using STL Decomposition
This data includes complex seasonality which STL handles automatically, but will be more difficult for other types of models. For that reason, I'll start with STL.

Below, the residuals are shown for a naive STL model with a trend window over the past week, and it does a good job of capturing the seasonality.  The ACF of residuals still shows a significant correlation at lag 1, so this model could be improved perhaps with some ARIMA terms, but overall this is pretty good.

```{r STL, fig.width=8}

fit_dcmp <- hourly_volume %>%
  filter_index("2022-01" ~ "2022-03-13") %>%
  model(stlf = decomposition_model(
    STL(Hourly_Volume ~ trend(window = 24*7), robust = TRUE),
    NAIVE(season_adjust)
  ))

fit_dcmp %>% gg_tsresiduals()

```

\pagebreak
## Forecast using Dynamic Harmonic Regression
This is a dynamic harmonic regression model fit to an ARIMA error structure, with 10 Fourier terms for the daily seasonal period, and 5 Fourier terms for the weekly seasonal period. The square root is used to ensure predictions remain positive.

The ACF of residuals shows a significant correlation at lag 24, which is the seasonal day period. This means the model could be improved still, but it does seem pretty good.

```{r}
fit_harmonic <- hourly_volume %>%
  filter_index("2022-01" ~ "2022-03-13") %>%
  model(
    dhr = ARIMA(sqrt(Hourly_Volume) ~ PDQ(0, 0, 0) + pdq(d = 0) +
                  fourier(period = 24, K = 10) +
                  fourier(period = 24*7, K = 5)))

fit_harmonic %>% gg_tsresiduals()

```


\pagebreak
## ARIMA

ARIMA has been commonly used to forecast traffic, but the complex seasonality makes setting up a model difficult. The first step is to find a differencing combination that results in stationary data.

```{r fig.height=8, fig.width=8}

transform <- hourly_volume %>%
  transmute(
    Volume = Hourly_Volume,
    Diff_1 = difference(Hourly_Volume, 1),
    Diff_day = difference(Hourly_Volume, 4*24),
    Diff_day_day = difference(difference(Hourly_Volume, 4*24), 4*24),
    Diff_week = difference(Hourly_Volume, 4*24*7),
    Diff_day_week = difference(difference(Hourly_Volume, 4*24), 4*24*7),
    Diff_day_1 = difference(difference(Hourly_Volume, 4*24), 1),
    Diff_week_1 = difference(difference(Hourly_Volume, 4*24*7), 1),
    Diff_day_week_1 = difference(difference(difference(Hourly_Volume, 1), 4*24), 4*24*7)
  )

transform %>% 
  filter_index("2022-03-18" ~.) %>%
  pivot_longer(cols=c(Volume, Diff_1, Diff_day, Diff_day_1, Diff_day_day), names_to = "key", values_to = "value") %>%
  autoplot(.vars = value) +
  facet_grid(vars(key), scales = "free_y")



  
```
\pagebreak

A KPSS test shows the double difference of the day period and 1 lag creates stationary data, but from plotin this double differenced data and the ACF/PACF it's actually clear that there is still seasonality present at the weekly level. The ACF and PACF both appear sinusoidal. 

```{r fig.width=8}
# Test if each transformation is stationary
#Volume, Diff_1, Diff_day, Diff_week, Diff_day_week, Diff_day_1, Diff_week_1, Diff_day_week_1
unitroot_kpss(transform$Diff_day_1)

#transform %>% fill_gaps() %>% ACF(Diff_day_1, lag_max = 96*7) %>% 
#  autoplot() + labs(title = "ACF of differencing by day, week, and 1 lag")

transform %>% fill_gaps() %>% filter_index("2022-02") %>%
  gg_tsdisplay(Diff_day_1, plot_type = "partial", lag = 24)


```

An ARIMA (1,1,3)(2,1,0)[24] had the lowest AIC, so it was selected for use. There is however autocorrelation in the residuals, so this model is not likley to work well. 

```{r}

fit_ARIMA <- hourly_volume %>%
  filter_index("2022-01" ~ "2022-03-13") %>%
  fill_gaps() %>%
    model(
      a1 = ARIMA(Hourly_Volume ~ pdq(1,0,3) + PDQ(2,1,0, period = 24)),
      a2 = ARIMA(Hourly_Volume ~ pdq(1,1,3) + PDQ(2,1,0, period = 24)),
      b1 = ARIMA(Hourly_Volume ~ pdq(4,0,0) + PDQ(2,1,0, period = 24)),
      b2 = ARIMA(Hourly_Volume ~ pdq(4,1,0) + PDQ(2,1,0, period = 24))
    )


fit_ARIMA %>% pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")

glance(fit_ARIMA) %>% arrange(AICc)


fit_ARIMA %>% select(a2) %>% gg_tsresiduals()



```



\pagebreak
# 5. Prediction

Prediction using STL model

```{r STL_prediction, fig.width=8}
fit_dcmp %>%
  forecast(h=24*7*2) %>%
  autoplot(hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))+
  labs(y = "Vehicles per Hour",
       title = "Actual Traffic Volume and STL Forecasted Volume")


accuracy(fit_dcmp %>% forecast(h=24*7*2), hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))
```

## Prediction using Dynamic Harmonic Regression 

```{r harmonic}
fit_harmonic %>%
  forecast(h=24*7*2) %>%
  autoplot(hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))+
  labs(y = "Vehicles per Hour",
       title = "Actual Traffic Volume and STL Forecasted Volume")

accuracy(fit_harmonic %>% forecast(h=24*7*2), hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))
```
 

## Prediction using ARIMA model

```{r ARIMA_prediction, fig.width=8}
fit_ARIMA %>%
  select(a2) %>%
  forecast(h=24*7*2) %>%
  autoplot(hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))+
  labs(y = "Vehicles per Hour",
       title = "Actual Traffic Volume and STL Forecasted Volume")


accuracy(fit_ARIMA %>% select(a2) %>% forecast(h=24*7*2), hourly_volume %>% filter_index("2022-03-07" ~ "2022-03-27"))
```



## Model Accuracy
The STL model was the most accurate, with a mean absolute percentage error of 7.8% vs 17.4% for dynamic harmonic regression, and 22.8% for ARIMA. The ARIMA model does did not work well because it does not account for the multiple seasonal periods present in the data. 